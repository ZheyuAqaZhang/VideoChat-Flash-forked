datasets:
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/image/LLaVA-ReCap-118K.jsonl
    sampling_strategy: first:10%
    data_root: OpenGVLab/stage2/LLaVA-ReCap-118K/data/extracted_images/
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/image/LLaVA-ReCap-CC3M.jsonl
    sampling_strategy: first:10%
    data_root: OpenGVLab/stage2/LLaVA-ReCap-CC3M/data/extracted_images/
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/image/LLaVA-ReCap-558K.jsonl
    sampling_strategy: first:10%
    data_root: OpenGVLab/stage2/LLaVA-ReCap-558K/data/extracted_images/
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/LLaVA-OneVision-Mid-Data/evol_instruct_processed.jsonl
    sampling_strategy: first:10%
  # - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/video/webvid-fuse_caption_2m.jsonl
  #   sampling_strategy: first:10%
  #   data_root: https://github.com/m-bain/webvid
  # - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/video/caption_sharegemini_webvid_core100k_clean.jsonl
  #   sampling_strategy: first:10%
  #   data_root: https://github.com/m-bain/webvid
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/video/caption_sharegemini_k400_223k.jsonl
    sampling_strategy: first:10%
    data_root: OpenGVLab/stage2/OpenMMLab___Kinetics-400/raw/Kinetics-400/videos_train/
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/image/ureader_tr_processed.jsonl
    data_root: OpenGVLab/stage2/LLaVA-OneVision-Mid-Data/ureader_tr/
    sampling_strategy: first:10%
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/image/synthdog_zh_processed.jsonl
    data_root: OpenGVLab/stage2/LLaVA-OneVision-Mid-Data/synthdog_zh/synthdog-zh/images/
    sampling_strategy: first:10%
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/image/synthdog_en_processed.jsonl
    data_root: OpenGVLab/stage2/LLaVA-OneVision-Mid-Data/synthdog_en/synthdog-en/alt-images/
    sampling_strategy: first:10%
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/video/smit_caption_481k.jsonl
    sampling_strategy: first:10%
    data_root: OpenGVLab/smit/S-MiT/
  - json_path: OpenGVLab/VideoChat-Flash-Training-Data/oreo/video/caption_sharegptvideo_300k-sharegptvideo-train_300k_302k.jsonl
    sampling_strategy: first:10%
    data_root: OpenGVLab/train_video_and_instruction/train_300k/
    video_read_type: img